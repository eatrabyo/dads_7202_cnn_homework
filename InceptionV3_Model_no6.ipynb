{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from glob import glob\n",
    "from dask import bag\n",
    "from dask.diagnostics import ProgressBar\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input,decode_predictions\n",
    "from IPython.display import SVG, Image\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'dataset/train/'\n",
    "TEST_PATH = 'dataset/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Check amount of data and data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "  TRAIN_PATH,\n",
    "  seed = 123,\n",
    "  image_size = (224, 224))\n",
    "\n",
    "print(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "for images, labels in train_ds.take(1):\n",
    "    # print(class_names[labels[2]])\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Class Imbalance: Numbers of Training Data for Each Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_train_classes = {\n",
    "'Caribou': len(os.listdir('dataset/train/caribou')),\n",
    "'Deer': len(os.listdir('dataset/train/deer')),\n",
    "'Elk': len(os.listdir('dataset/train/elk')),\n",
    "'Moose': len(os.listdir('dataset/train/moose'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(number_train_classes.keys(), number_train_classes.values(), width = .5);\n",
    "plt.title(\"Number of Images by Train Class\");\n",
    "plt.xlabel('Class Name');\n",
    "plt.ylabel('# Images');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Class Imbalance: Numbers of Testing Data for Each Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_test_classes = {\n",
    "'Caribou': len(os.listdir('dataset/train/caribou')),\n",
    "'Deer': len(os.listdir('dataset/train/deer')),\n",
    "'Elk': len(os.listdir('dataset/train/elk')),\n",
    "'Moose': len(os.listdir('dataset/train/moose'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(number_test_classes.keys(), number_test_classes.values(), width = .5);\n",
    "plt.title(\"Number of Images by Test Class\");\n",
    "plt.xlabel('Class Name');\n",
    "plt.ylabel('# Images');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Image Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from glob import glob\n",
    "from dask import bag\n",
    "from dask.diagnostics import ProgressBar\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_images = dict()\n",
    "for dirpath, _, filenames in os.walk(TRAIN_PATH):\n",
    "    for path_image in filenames:\n",
    "        image = os.path.abspath(os.path.join(dirpath, path_image))\n",
    "        with Image.open(image) as img:\n",
    "            width, height = img.size\n",
    "            train_size_images[path_image] = {'width': width, 'height': height,'path':dirpath}\n",
    "train_size_images = pd.DataFrame.from_dict(train_size_images,'index')\n",
    "train_size_images.reset_index(inplace=True)\n",
    "train_size_images[['folder','subfolder','class']] = train_size_images['path'].str.split('/',n=3,expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_lst = list(train_size_images['class'].unique())\n",
    "fig, ax = plt.subplots(2, 2, figsize = (10, 5))\n",
    "fig.tight_layout(pad=4.0)\n",
    "ax = ax.ravel()\n",
    "for idx,c in enumerate(class_lst,0):\n",
    "    tempdf = train_size_images.loc[train_size_images['class'] == c]\n",
    "    ax[idx].plot(tempdf['width'],tempdf['height'],'o')\n",
    "    ax[idx].set_xlabel('Width')\n",
    "    ax[idx].set_ylabel('Height')\n",
    "    ax[idx].set_title(c)\n",
    "fig.suptitle(\"Train Dataset Image's Size\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_images = dict()\n",
    "for dirpath, _, filenames in os.walk(TEST_PATH):\n",
    "    for path_image in filenames:\n",
    "        image = os.path.abspath(os.path.join(dirpath, path_image))\n",
    "        with Image.open(image) as img:\n",
    "            width, height = img.size\n",
    "            test_size_images[path_image] = {'width': width, 'height': height,'path':dirpath}\n",
    "test_size_df = pd.DataFrame.from_dict(test_size_images,'index')\n",
    "test_size_df.reset_index(inplace=True)\n",
    "test_size_df[['folder','subfolder','class']] = test_size_df['path'].str.split('/',n=3,expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_lst = list(test_size_df['class'].unique())\n",
    "fig, ax = plt.subplots(2, 2, figsize = (10, 5))\n",
    "fig.tight_layout(pad=4.0)\n",
    "ax = ax.ravel()\n",
    "for idx,c in enumerate(class_lst,0):\n",
    "    tempdf = test_size_df.loc[test_size_df['class'] == c]\n",
    "    ax[idx].plot(tempdf['width'],tempdf['height'],'o')\n",
    "    ax[idx].set_xlabel('Width')\n",
    "    ax[idx].set_ylabel('Height')\n",
    "    ax[idx].set_title(c)\n",
    "fig.suptitle(\"Test Dataset Image's Size\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Image color types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = {\n",
    "    'caribou': TRAIN_PATH + '/caribou/',\n",
    "    'deer': TRAIN_PATH + '/deer/',\n",
    "    'elk': TRAIN_PATH + '/elk/',\n",
    "    'moose': TRAIN_PATH + '/moose/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_type(image_path):\n",
    "    \"\"\"\n",
    "    Determine if an image is 'grayscale' or 'rgb'.\n",
    "    \"\"\"\n",
    "    im = Image.open(image_path)\n",
    "    arr = np.array(im)\n",
    "    if len(arr.shape) == 2:\n",
    "        return 'grayscale'\n",
    "    elif len(arr.shape) == 3 and arr.shape[2] == 3:\n",
    "        return 'rgb'\n",
    "    else:\n",
    "        return 'other'  # Might catch cases like RGBA or other unexpected formats.\n",
    " \n",
    "def count_image_types_and_get_grayscale_filenames(directory_path):\n",
    "    \"\"\"\n",
    "    Count the number of 'grayscale' and 'rgb' images in a directory and\n",
    "    return filenames of 'grayscale' images.\n",
    "    \"\"\"\n",
    "    grayscale_count = 0\n",
    "    rgb_count = 0\n",
    "    grayscale_filenames = []\n",
    " \n",
    "    for fname in os.listdir(directory_path):\n",
    "        image_path = os.path.join(directory_path, fname)\n",
    "        img_type = get_image_type(image_path)\n",
    "        if img_type == 'grayscale':\n",
    "            grayscale_count += 1\n",
    "            grayscale_filenames.append(fname)\n",
    "        elif img_type == 'rgb':\n",
    "            rgb_count += 1\n",
    " \n",
    "    return grayscale_count, rgb_count, grayscale_filenames\n",
    " \n",
    "# Loop through each directory and count image types\n",
    "for animal, dir_path in directories.items():\n",
    "    grayscale_count, rgb_count, grayscale_files = count_image_types_and_get_grayscale_filenames(dir_path)\n",
    "    print(f\"For {animal}:\")\n",
    "    print(f\"Number of grayscale images: {grayscale_count}\")\n",
    "    print(f\"Number of RGB images: {rgb_count}\")\n",
    "    print(f\"Filenames of grayscale images: {grayscale_files}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing: Reading images for Trainning and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    "    label_mode = 'int',\n",
    "    seed = 123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "print(train_ds.class_names)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    "    label_mode = 'int',\n",
    "    seed = 123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "print(val_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = image_dataset_from_directory(\n",
    "  'dataset/test/',\n",
    "  seed=123,\n",
    "  image_size=(224, 224))\n",
    "\n",
    "print(test_ds.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaug_train = tf.keras.models.Sequential( [\n",
    "                                          tf.keras.Input(shape=(224,224,3)),\n",
    "                                          tf.keras.layers.RandomFlip(mode='horizontal', name='rand_flip'),\n",
    "                                          tf.keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='nearest', name='rand_trans'),\n",
    "                                          tf.keras.layers.RandomRotation(factor=0.1, fill_mode='nearest', name='rand_rot'),\n",
    "                                          tf.keras.layers.RandomZoom(height_factor=0.1,fill_mode='nearest'),\n",
    "                                          tf.keras.layers.RandomBrightness(0.2),\n",
    "                                          tf.keras.layers.Rescaling(1./255)\n",
    "                                      ],\n",
    "                                     name='dataaug' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaug_val = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Rescaling(scale =1./255),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train = train_ds.map(lambda x,y: (dataaug_train(x,training=True),y))\n",
    "augmented_val = train_ds.map(lambda x,y: (dataaug_val(x,training=True),y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show original vs resized\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10,5))\n",
    "ax = ax.ravel()\n",
    "for images, labels in augmented_train:\n",
    "    for i in range(6):\n",
    "        ax[i].imshow(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_ds = train_ds.concatenate(augmented_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = full_train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = val_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images, labels):\n",
    "  return preprocess_input(images), labels\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "val_ds = validation_dataset.map(preprocess)\n",
    "test_ds = test_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception V3 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncV3 = InceptionV3(include_top = False, weights = \"imagenet\", input_shape = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in IncV3.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(IncV3.layers):\n",
    "    print( f\"Layer {i}: name = {layer.name} , trainable = {layer.trainable}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncV3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = IncV3.output\n",
    "\n",
    "x = tf.keras.layers.Flatten()(model_output)\n",
    "x = tf.keras.layers.Dense(2048, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "new_outputs = tf.keras.layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "# Construct the main model\n",
    "model = tf.keras.models.Model(inputs = IncV3.inputs, outputs = new_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_filepath = \"inception_callback/bestmodel_epoch{epoch:02d}_valloss{val_loss:.2f}.weights.h5\"\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 2, mode = 'max')\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.1, patience = 1, mode = 'min')\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor = 'val_accuracy', mode = 'max', save_best_only = True, save_weight_only = False, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "           augmented_train.repeat(), steps_per_epoch=int(2000/batch_size), \n",
    "           epochs = 30, validation_data = val_ds.repeat(), \n",
    "           validation_steps=int(2000/batch_size), callbacks=[lr_reduce, checkpoint], verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.evaluate(test_ds)\n",
    "print(f'{model.metrics_names}: {test_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START NO.6 HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the BEST_MODEL_NAME before run this ce11 !!!\n",
    "\n",
    "model = load_model('BEST_MODEL_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "start_tune = 1\n",
    "stop_tune = 300\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in model.layers[start_tune:stop_tune]:\n",
    "  layer.trainable = False\n",
    "\n",
    "#for layer in base_model.layers:\n",
    "#  if layer.__class__.__name__ in [\"BatchNormalization\"]:\n",
    "#    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial weight\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "layer = layers.Dense(\n",
    "    units=64,\n",
    "    kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "    bias_initializer=initializers.Zeros()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "           augmented_train.repeat(), steps_per_epoch=int(2000/batch_size), \n",
    "           epochs = 30, validation_data = val_ds.repeat(), \n",
    "           validation_steps=int(2000/batch_size), callbacks=[lr_reduce, checkpoint], verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.evaluate(test_ds)\n",
    "print(f'{model.metrics_names}: {test_result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
